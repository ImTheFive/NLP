{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 导入工具包\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 读入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x为训练图像的占位符、y_为训练图像标签的占位符\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 将单张图片从784维向量重新还原为28x28的矩阵图片\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "\n",
    "#定义第一层卷积层信道为6\n",
    "out_channl1 = 32\n",
    "# 第一层卷积层\n",
    "W_conv1 = weight_variable([5, 5, 1, out_channl1])\n",
    "b_conv1 = bias_variable([out_channl1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "#定义第二层卷积层信道为16\n",
    "out_channl2 = 64\n",
    "# 第二层卷积层\n",
    "W_conv2 = weight_variable([5, 5, out_channl1, out_channl2])\n",
    "b_conv2 = bias_variable([out_channl2])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义全连接层函数\n",
    "\n",
    "def fcn_layer(inputs,           # 输入数据\n",
    "               input_dim,        # 输入神经元数量\n",
    "               output_dim,       # 输出神经元数量\n",
    "               activation=None):  # 激活函数\n",
    "    # 以截断正态分布的随机数初始化W\n",
    "    W = tf.truncated_normal([input_dim, output_dim], stddev=0.1)\n",
    "\n",
    "    # 以0初始化b\n",
    "    b = tf.constant(0.1, shape=[output_dim])\n",
    "    \n",
    "    # 前置计算\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    \n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "# 全连接层，输出为120维的向量\n",
    "out_num = 1024\n",
    "input_num = h_pool2.shape[1]*h_pool2.shape[2]*h_pool2.shape[3]\n",
    "print(input_num)\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, input_num])\n",
    "h_fc1 = fcn_layer(h_pool2_flat, int(input_num), out_num, tf.nn.relu)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([out_num, 10]))\n",
    "# 以0初始化b\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "# 前置计算\n",
    "forword = tf.matmul(h_fc1, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4f1737c3640e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "#设置训练参数\n",
    "train_epochs = 2000 #训练轮数\n",
    "batch_size = 50 #单次训练样本数（批次大小）\n",
    "total_batch = int(mnist.train.num_examples/batch_size) # 一轮训练有多少批次\n",
    "display_step = 10 #显示粒度\n",
    "learning_rate = 1e-4 #学习率\n",
    "\n",
    "pred = tf.nn.softmax(forword)\n",
    "\n",
    "#定义交叉熵损失函数\n",
    "loss_function = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(logits=forword,labels=y_))\n",
    "\n",
    "#梯度下降优化器\n",
    "optimizer  = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)\n",
    "\n",
    "#检查预测类别\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1),tf.argmax(y_, 1))\n",
    "\n",
    "#准确率，讲布尔值转化为浮点数，计算平均值\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session() #声明会话\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer() #初始化变量\n",
    "sess.run(init)\n",
    "\n",
    "xs, ys = mnist.train.next_batch(50)\n",
    "accuracy.eval(feed_dict={x: xs, y_: ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 loss= 0.12800555  Accuracy= 0.968\n",
      "Train Epoch: 20 loss= 0.2230892  Accuracy= 0.9606\n",
      "Train Epoch: 30 loss= 0.26347908  Accuracy= 0.9736\n",
      "Train Epoch: 40 loss= 0.47903994  Accuracy= 0.9728\n",
      "Train Epoch: 50 loss= 0.43396434  Accuracy= 0.9778\n",
      "Train Epoch: 60 loss= 0.4775855  Accuracy= 0.9738\n",
      "Train Epoch: 70 loss= 0.6631239  Accuracy= 0.975\n",
      "Train Epoch: 80 loss= 0.83752245  Accuracy= 0.9732\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8e898b072d10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#读取批次数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#执行批次训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#total_batch个批次训练完成后，使用验证数据计算误差与准确率；验证集没有分批\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     loss,acc = sess.run([loss_function,accuracy],\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "for epoch in range(train_epochs):\n",
    "    for batch in range(total_batch):\n",
    "        xs, ys = mnist.train.next_batch(batch_size)#读取批次数据\n",
    "        sess.run(optimizer, feed_dict={x:xs,y_:ys}) #执行批次训练\n",
    "    #total_batch个批次训练完成后，使用验证数据计算误差与准确率；验证集没有分批\n",
    "\n",
    "    #打印训练过程中的详细信息\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        loss,acc = sess.run([loss_function,accuracy],\n",
    "                       feed_dict={x:mnist.validation.images,y_:mnist.validation.labels})\n",
    "        print(\"Train Epoch:\", epoch+1, \"loss=\", loss,\" Accuracy=\",acc)\n",
    "        \n",
    "print(\"Train Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method run in module tensorflow.python.client.session:\n",
      "\n",
      "run(fetches, feed_dict=None, options=None, run_metadata=None) method of tensorflow.python.client.session.Session instance\n",
      "    Runs operations and evaluates tensors in `fetches`.\n",
      "    \n",
      "    This method runs one \"step\" of TensorFlow computation, by\n",
      "    running the necessary graph fragment to execute every `Operation`\n",
      "    and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      "    `feed_dict` for the corresponding input values.\n",
      "    \n",
      "    The `fetches` argument may be a single graph element, or an arbitrarily\n",
      "    nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      "    elements at its leaves.  A graph element can be one of the following types:\n",
      "    \n",
      "    * An @{tf.Operation}.\n",
      "      The corresponding fetched value will be `None`.\n",
      "    * A @{tf.Tensor}.\n",
      "      The corresponding fetched value will be a numpy ndarray containing the\n",
      "      value of that tensor.\n",
      "    * A @{tf.SparseTensor}.\n",
      "      The corresponding fetched value will be a\n",
      "      @{tf.SparseTensorValue}\n",
      "      containing the value of that sparse tensor.\n",
      "    * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      "      numpy ndarray containing the handle of that tensor.\n",
      "    * A `string` which is the name of a tensor or operation in the graph.\n",
      "    \n",
      "    The value returned by `run()` has the same shape as the `fetches` argument,\n",
      "    where the leaves are replaced by the corresponding values returned by\n",
      "    TensorFlow.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    ```python\n",
      "       a = tf.constant([10, 20])\n",
      "       b = tf.constant([1.0, 2.0])\n",
      "       # 'fetches' can be a singleton\n",
      "       v = session.run(a)\n",
      "       # v is the numpy array [10, 20]\n",
      "       # 'fetches' can be a list.\n",
      "       v = session.run([a, b])\n",
      "       # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      "       # 1-D array [1.0, 2.0]\n",
      "       # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      "       MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      "       v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      "       # v is a dict with\n",
      "       # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      "       # 'b' (the numpy array [1.0, 2.0])\n",
      "       # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      "       # [10, 20].\n",
      "    ```\n",
      "    \n",
      "    The optional `feed_dict` argument allows the caller to override\n",
      "    the value of tensors in the graph. Each key in `feed_dict` can be\n",
      "    one of the following types:\n",
      "    \n",
      "    * If the key is a @{tf.Tensor}, the\n",
      "      value may be a Python scalar, string, list, or numpy ndarray\n",
      "      that can be converted to the same `dtype` as that\n",
      "      tensor. Additionally, if the key is a\n",
      "      @{tf.placeholder}, the shape of\n",
      "      the value will be checked for compatibility with the placeholder.\n",
      "    * If the key is a\n",
      "      @{tf.SparseTensor},\n",
      "      the value should be a\n",
      "      @{tf.SparseTensorValue}.\n",
      "    * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      "      should be a nested tuple with the same structure that maps to their\n",
      "      corresponding values as above.\n",
      "    \n",
      "    Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      "    of the corresponding key.\n",
      "    \n",
      "    The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      "    allow controlling the behavior of this particular step (e.g. turning tracing\n",
      "    on).\n",
      "    \n",
      "    The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      "    appropriate, the non-Tensor output of this step will be collected there. For\n",
      "    example, when users turn on tracing in `options`, the profiled info will be\n",
      "    collected into this argument and passed back.\n",
      "    \n",
      "    Args:\n",
      "      fetches: A single graph element, a list of graph elements,\n",
      "        or a dictionary whose values are graph elements or lists of graph\n",
      "        elements (described above).\n",
      "      feed_dict: A dictionary that maps graph elements to values\n",
      "        (described above).\n",
      "      options: A [`RunOptions`] protocol buffer\n",
      "      run_metadata: A [`RunMetadata`] protocol buffer\n",
      "    \n",
      "    Returns:\n",
      "      Either a single value if `fetches` is a single graph element, or\n",
      "      a list of values if `fetches` is a list, or a dictionary with the\n",
      "      same keys as `fetches` if that is a dictionary (described above).\n",
      "      Order in which `fetches` operations are evaluated inside the call\n",
      "      is undefined.\n",
      "    \n",
      "    Raises:\n",
      "      RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "        closed).\n",
      "      TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "      ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      "        `Tensor` that doesn't exist.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sess.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
